% Related Work
% Organize by themes/categories, not paper-by-paper
% Show how your work builds on, differs from, or fills gaps in existing work

\label{sec:related}

% Introduction to related work
Research on Wikipedia has examined its community structure, editorial governance, and systemic bias across topics and languages. Scholars have long noted that while Wikipedia aspires to neutrality, it reflects the perspectives of its contributors and the linguistic communities that sustain it. Recent work has expanded beyond governance to explore how multilingual differences and translation asymmetries introduce subtle forms of cultural and ideological bias.

\subsection{Wikipedia Governance and Community Culture}

Reagle’s foundational study, \textit{Good Faith Collaboration}~\cite{reagle2010good}, explores how Wikipedia’s open editing model and community norms support collaboration and self-governance. These practices, while promoting transparency and participation, also create conditions where biases can emerge through consensus-driven editing. Studies of Wikipedia governance have shown that editorial authority and content decisions are unevenly distributed, often reflecting dominant language groups or cultural perspectives. This line of research establishes the foundation for understanding how community-driven systems can both sustain openness and reproduce bias.

\subsection{Linguistic and Ideological Bias on Wikipedia}

Beyond governance, recent analyses have focused on how bias manifests linguistically. The Wikipedia article on ideological bias~\cite{wikipedia2024ideologicalbias} summarizes political and cultural asymmetries across the platform, highlighting ongoing debates about neutrality. The Johns Hopkins University Hub report~\cite{jhu2025wikipediabias} provides empirical evidence that Wikipedia’s multilingual content contains translation and framing differences shaped by cultural contexts. Similarly, New Scientist~\cite{newscientist2016wikipedialanguage} demonstrates that facts and emphasis vary across language editions, influencing how topics are understood by readers in different regions. Together, these works show that language is a key factor in how bias operates within Wikipedia’s ecosystem.

\subsection{Our Work in Context}

While prior research identifies systemic and linguistic bias in Wikipedia, few studies have directly compared multilingual article content using live data from the Wikipedia API. Our project extends this discussion by developing a simple computational framework to observe real-time differences between English, Japanese, and Spanish articles. By combining existing scholarship on governance and ideological bias with direct programmatic analysis, we provide a practical demonstration of how language shapes the representation of information. This work contributes to a growing effort to make Wikipedia’s multilingual landscape more transparent, equitable, and linguistically aware.
